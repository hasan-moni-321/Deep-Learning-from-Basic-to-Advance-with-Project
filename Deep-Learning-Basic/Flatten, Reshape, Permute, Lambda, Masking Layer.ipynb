{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flatten Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is a layer that flat previous layers output                                                                        \n",
    "\n",
    "Example:                                                                                                                 \n",
    "    [[2,3,5],                                                                                                                 \n",
    "     [6,8,5],                                                                                                           \n",
    "     [4,6,5]]                                                                                                                     \n",
    "    \n",
    "convert into flat, that looks like,                                                                                                      \n",
    "[2,3,5,6,8,5,4,6,5]                                                                                                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is used one time in Neural Network, before two-three layer of the end                                             \n",
    "\n",
    "Example: \n",
    "    \n",
    "    Conv2D                                                                                                             \n",
    "    MaxPooling2D                                                                                                                                                                                                                        \n",
    "    Dropout                                                                                                             \n",
    "    \n",
    "    Conv2D                                                                                                                    \n",
    "    MaxPooling2D                                                                                                          \n",
    "    Dropout                                                                                                                       \n",
    "    \n",
    "    Conv2D                                                                                                             \n",
    "    MaxPooling2D                                                                                                                 \n",
    "    Dropout                                                                                                           \n",
    "    \n",
    "    Flatten                                                                                                             \n",
    "    Dense                                                                                                                                                                                                                               \n",
    "    Dense                                                                                                          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: In between the convolutional layer and the fully connected layer, there is a flatten layer. Flatten transform a two dimensional matrix of features into a vector  that can be fed into a fully connected neural network classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reshape Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Reshape Layer is used to resize the data                                                                                             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example:                                                                                                              \n",
    "    \n",
    "a pic with dimension(None,13,13,1024) convert it to the dimension(4,10)                                                             \n",
    "\n",
    "Ans:                                                                                                                   \n",
    "    Flatten() (13*13*1024=173056)                                                                                                 \n",
    "    Dense()  (4*10=40)                                                                                                                         \n",
    "    Reshape () (4,10)   #where 4 rows and 10 columns                                                                                                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Permute Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Permutes the dimensions of the input according to a given pattern.\n",
    "\n",
    "Useful for e.g. connecting RNNs and convnets together.\n",
    "\n",
    "Example:\n",
    "    \n",
    "    model = Sequential()\n",
    "model.add(Permute((2, 1), input_shape=(10, 64)))\n",
    "# now: model.output_shape == (None, 64, 10)\n",
    "# note: `None` is the batch dimension\n",
    "\n",
    "Arguments:\n",
    "\n",
    "    dims: Tuple of integers. Permutation pattern, does not include the samples dimension. \n",
    "        Indexing starts at 1. For instance, (2, 1) permutes the first and second dimensions of the input.\n",
    "        \n",
    "    Input shape:\n",
    "    Arbitrary. Use the keyword argument input_shape (tuple of integers, does not include the samples axis) \n",
    "    when using this layer as the first layer in a model.\n",
    "\n",
    "    Output shape:\n",
    "    Same as the input shape, but with the dimensions re-ordered according to the specified pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lambda Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Keras provides a lambda layer; it can wrap a function of your choosing. For example, if you wanted to build a \n",
    "layer that squares its input tensor element-wise, you can say simply:\n",
    "\n",
    "model.add(lambda(lambda x: x ** 2))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Masking Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Masking allows us to handle variable length inputs in RNNs. Although RNNs can handle variable length inputs, \n",
    "they still need fixed length inputs. Therefore, what we do is to create a mask per sample initialised with 0 \n",
    "with a length equal to the longest sequence in the dataset. Then we fill the mask with 1s to all the position \n",
    "where the sample has values in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example,\n",
    "\n",
    "The longest sequence in a dataset is 10, thus the masks will be initialised as follows:\n",
    "\n",
    "mask = [ 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]\n",
    "\n",
    "we also have a sample:\n",
    "\n",
    "a = [ 2., 0. ,5. ,6. ]\n",
    "\n",
    "now we fill the mask with ones to all the positions a has values in. Therefore we get the following mask:\n",
    "\n",
    "mask_a = [ 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.]\n",
    "\n",
    "After that, we feed the sample and the mask to a RNN. Under the hood, the RNNs is going to add 0 to all the positions a doesnâ€™t have values in so a will turn into\n",
    "\n",
    "a_hood = [ 2., 0. ,5. ,6., 0., 0., 0., 0., 0., 0.]\n",
    "\n",
    "However, if we leave it as it is, the RNN is going to think the sequence has length 10 and use all the appended 0s.\n",
    "\n",
    "mask_a = [ 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.]\n",
    "\n",
    "The mask_a is going to be used to skip any input with mask 0 by copying the previous hidden state of the cell; it will proceed normally for any input with mask 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
