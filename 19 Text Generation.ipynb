{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XbAREX1-cAyg"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5Uz_USSsi0VC"
   },
   "source": [
    "Develop a Small LSTM Recurrent Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "so0DdjcliXSr"
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "phwK6f9FiXcS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZwFDeaR0R5bD"
   },
   "source": [
    "## Reading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XLj0O5ajiX_g"
   },
   "outputs": [],
   "source": [
    "# load ascii text and covert to lowercase\n",
    "filename = \"/content/drive/My Drive/to-download/the end.txt\"\n",
    "raw_text = open(filename).read()\n",
    "raw_text = raw_text.lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 192
    },
    "colab_type": "code",
    "id": "XUVI0HLViYFt",
    "outputId": "5f1335d5-570f-4e77-f3a4-a005d54d8e3d"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic": {
       "type": "string"
      },
      "text/plain": [
       "'end of project gutenberg\\'s alice\\'s adventures in wonderland, by lewis carroll\\n\\n*** end of this project gutenberg ebook alice\\'s adventures in wonderland ***\\n\\n***** this file should be named 11.txt or 11.zip *****\\nthis and all associated files of various formats will be found in:\\n        http://www.gutenberg.org/1/11/\\n\\n\\n\\nupdated editions will replace the previous one--the old editions\\nwill be renamed.\\n\\ncreating the works from public domain print editions means that no\\none owns a united states copyright in these works, so the foundation\\n(and you!) can copy and distribute it in the united states without\\npermission and without paying copyright royalties.  special rules,\\nset forth in the general terms of use part of this license, apply to\\ncopying and distributing project gutenberg-tm electronic works to\\nprotect the project gutenberg-tm concept and trademark.  project\\ngutenberg is a registered trademark, and may not be used if you\\ncharge for the ebooks, unless you receive specific permission.  if you\\ndo not charge anything for copies of this ebook, complying with the\\nrules is very easy.  you may use this ebook for nearly any purpose\\nsuch as creation of derivative works, reports, performances and\\nresearch.  they may be modified and printed and given away--you may do\\npractically anything with public domain ebooks.  redistribution is\\nsubject to the trademark license, especially commercial\\nredistribution.\\n\\n\\n\\n*** start: full license ***\\n\\nthe full project gutenberg license\\nplease read this before you distribute or use this work\\n\\nto protect the project gutenberg-tm mission of promoting the free\\ndistribution of electronic works, by using or distributing this work\\n(or any other work associated in any way with the phrase \"project\\ngutenberg\"), you agree to comply with all the terms of the full project\\ngutenberg-tm license (available with this file or online at\\nhttp://gutenberg.org/license).\\n\\n\\nsection 1.  general terms of use and redistributing project gutenberg-tm\\nelectronic works\\n\\n1.a.  by reading or using any part of this project gutenberg-tm\\nelectronic work, you indicate that you have read, understand, agree to\\nand accept all the terms of this license and intellectual property\\n(trademark/copyright) agreement.  if you do not agree to abide by all\\nthe terms of this agreement, you must cease using and return or destroy\\nall copies of project gutenberg-tm electronic works in your possession.\\nif you paid a fee for obtaining a copy of or access to a project\\ngutenberg-tm electronic work and you do not agree to be bound by the\\nterms of this agreement, you may obtain a refund from the person or\\nentity to whom you paid the fee as set forth in paragraph 1.e.8.\\n\\n1.b.  \"project gutenberg\" is a registered trademark.  it may only be\\nused on or associated in any way with an electronic work by people who\\nagree to be bound by the terms of this agreement.  there are a few\\nthings that you can do with most project gutenberg-tm electronic works\\neven without complying with the full terms of this agreement.  see\\nparagraph 1.c below.  there are a lot of things you can do with project\\ngutenberg-tm electronic works if you follow the terms of this agreement\\nand help preserve free future access to project gutenberg-tm electronic\\nworks.  see paragraph 1.e below.\\n\\n1.c.  the project gutenberg literary archive foundation (\"the foundation\"\\nor pglaf), owns a compilation copyright in the collection of project\\ngutenberg-tm electronic works.  nearly all the individual works in the\\ncollection are in the public domain in the united states.  if an\\nindividual work is in the public domain in the united states and you are\\nlocated in the united states, we do not claim a right to prevent you from\\ncopying, distributing, performing, displaying or creating derivative\\nworks based on the work as long as all references to project gutenberg\\nare removed.  of course, we hope that you will support the project\\ngutenberg-tm mission of promoting free access to electronic works by\\nfreely sharing project gutenberg-tm works in compliance with the terms of\\nthis agreement for keeping the project gutenberg-tm name associated with\\nthe work.  you can easily comply with the terms of this agreement by\\nkeeping this work in the same format with its attached full project\\ngutenberg-tm license when you share it without charge with others.\\n\\n1.d.  the copyright laws of the place where you are located also govern\\nwhat you can do with this work.  copyright laws in most countries are in\\na constant state of change.  if you are outside the united states, check\\nthe laws of your country in addition to the terms of this agreement\\nbefore downloading, copying, displaying, performing, distributing or\\ncreating derivative works based on this work or any other project\\ngutenberg-tm work.  the foundation makes no representations concerning\\nthe copyright status of any work in any country outside the united\\nstates.\\n\\n1.e.  unless you have removed all references to project gutenberg:\\n\\n1.e.1.  the following sentence, with active links to, or other immediate\\naccess to, the full project gutenberg-tm license must appear prominently\\nwhenever any copy of a project gutenberg-tm work (any work on which the\\nphrase \"project gutenberg\" appears, or with which the phrase \"project\\ngutenberg\" is associated) is accessed, displayed, performed, viewed,\\ncopied or distributed:\\n\\nthis ebook is for the use of anyone anywhere at no cost and with\\nalmost no restrictions whatsoever.  you may copy it, give it away or\\nre-use it under the terms of the project gutenberg license included\\nwith this ebook or online at www.gutenberg.org\\n\\n1.e.2.  if an individual project gutenberg-tm electronic work is derived\\nfrom the public domain (does not contain a notice indicating that it is\\nposted with permission of the copyright holder), the work can be copied\\nand distributed to anyone in the united states without paying any fees\\nor charges.  if you are redistributing or providing access to a work\\nwith the phrase \"project gutenberg\" associated with or appearing on the\\nwork, you must comply either with the requirements of paragraphs 1.e.1\\nthrough 1.e.7 or obtain permission for the use of the work and the\\nproject gutenberg-tm trademark as set forth in paragraphs 1.e.8 or\\n1.e.9.\\n\\n1.e.3.  if an individual project gutenberg-tm electronic work is posted\\nwith the permission of the copyright holder, your use and distribution\\nmust comply with both paragraphs 1.e.1 through 1.e.7 and any additional\\nterms imposed by the copyright holder.  additional terms will be linked\\nto the project gutenberg-tm license for all works posted with the\\npermission of the copyright holder found at the beginning of this work.\\n\\n1.e.4.  do not unlink or detach or remove the full project gutenberg-tm\\nlicense terms from this work, or any files containing a part of this\\nwork or any other work associated with project gutenberg-tm.\\n\\n1.e.5.  do not copy, display, perform, distribute or redistribute this\\nelectronic work, or any part of this electronic work, without\\nprominently displaying the sentence set forth in paragraph 1.e.1 with\\nactive links or immediate access to the full terms of the project\\ngutenberg-tm license.\\n\\n1.e.6.  you may convert to and distribute this work in any binary,\\ncompressed, marked up, nonproprietary or proprietary form, including any\\nword processing or hypertext form.  however, if you provide access to or\\ndistribute copies of a project gutenberg-tm work in a format other than\\n\"plain vanilla ascii\" or other format used in the official version\\nposted on the official project gutenberg-tm web site (www.gutenberg.org),\\nyou must, at no additional cost, fee or expense to the user, provide a\\ncopy, a means of exporting a copy, or a means of obtaining a copy upon\\nrequest, of the work in its original \"plain vanilla ascii\" or other\\nform.  any alternate format must include the full project gutenberg-tm\\nlicense as specified in paragraph 1.e.1.\\n\\n1.e.7.  do not charge a fee for access to, viewing, displaying,\\nperforming, copying or distributing any project gutenberg-tm works\\nunless you comply with paragraph 1.e.8 or 1.e.9.\\n\\n1.e.8.  you may charge a reasonable fee for copies of or providing\\naccess to or distributing project gutenberg-tm electronic works provided\\nthat\\n\\n- you pay a royalty fee of 20% of the gross profits you derive from\\n     the use of project gutenberg-tm works calculated using the method\\n     you already use to calculate your applicable taxes.  the fee is\\n     owed to the owner of the project gutenberg-tm trademark, but he\\n     has agreed to donate royalties under this paragraph to the\\n     project gutenberg literary archive foundation.  royalty payments\\n     must be paid within 60 days following each date on which you\\n     prepare (or are legally required to prepare) your periodic tax\\n     returns.  royalty payments should be clearly marked as such and\\n     sent to the project gutenberg literary archive foundation at the\\n     address specified in section 4, \"information about donations to\\n     the project gutenberg literary archive foundation.\"\\n\\n- you provide a full refund of any money paid by a user who notifies\\n     you in writing (or by e-mail) within 30 days of receipt that s/he\\n     does not agree to the terms of the full project gutenberg-tm\\n     license.  you must require such a user to return or\\n     destroy all copies of the works possessed in a physical medium\\n     and discontinue all use of and all access to other copies of\\n     project gutenberg-tm works.\\n\\n- you provide, in accordance with paragraph 1.f.3, a full refund of any\\n     money paid for a work or a replacement copy, if a defect in the\\n     electronic work is discovered and reported to you within 90 days\\n     of receipt of the work.\\n\\n- you comply with all other terms of this agreement for free\\n     distribution of project gutenberg-tm works.\\n\\n1.e.9.  if you wish to charge a fee or distribute a project gutenberg-tm\\nelectronic work or group of works on different terms than are set\\nforth in this agreement, you must obtain permission in writing from\\nboth the project gutenberg literary archive foundation and michael\\nhart, the owner of the project gutenberg-tm trademark.  contact the\\nfoundation as set forth in section 3 below.\\n\\n1.f.\\n\\n1.f.1.  project gutenberg volunteers and employees expend considerable\\neffort to identify, do copyright research on, transcribe and proofread\\npublic domain works in creating the project gutenberg-tm\\ncollection.  despite these efforts, project gutenberg-tm electronic\\nworks, and the medium on which they may be stored, may contain\\n\"defects,\" such as, but not limited to, incomplete, inaccurate or\\ncorrupt data, transcription errors, a copyright or other intellectual\\nproperty infringement, a defective or damaged disk or other medium, a\\ncomputer virus, or computer codes that damage or cannot be read by\\nyour equipment.\\n\\n1.f.2.  limited warranty, disclaimer of damages - except for the \"right\\nof replacement or refund\" described in paragraph 1.f.3, the project\\ngutenberg literary archive foundation, the owner of the project\\ngutenberg-tm trademark, and any other party distributing a project\\ngutenberg-tm electronic work under this agreement, disclaim all\\nliability to you for damages, costs and expenses, including legal\\nfees.  you agree that you have no remedies for negligence, strict\\nliability, breach of warranty or breach of contract except those\\nprovided in paragraph f3.  you agree that the foundation, the\\ntrademark owner, and any distributor under this agreement will not be\\nliable to you for actual, direct, indirect, consequential, punitive or\\nincidental damages even if you give notice of the possibility of such\\ndamage.\\n\\n1.f.3.  limited right of replacement or refund - if you discover a\\ndefect in this electronic work within 90 days of receiving it, you can\\nreceive a refund of the money (if any) you paid for it by sending a\\nwritten explanation to the person you received the work from.  if you\\nreceived the work on a physical medium, you must return the medium with\\nyour written explanation.  the person or entity that provided you with\\nthe defective work may elect to provide a replacement copy in lieu of a\\nrefund.  if you received the work electronically, the person or entity\\nproviding it to you may choose to give you a second opportunity to\\nreceive the work electronically in lieu of a refund.  if the second copy\\nis also defective, you may demand a refund in writing without further\\nopportunities to fix the problem.\\n\\n1.f.4.  except for the limited right of replacement or refund set forth\\nin paragraph 1.f.3, this work is provided to you \\'as-is\\' with no other\\nwarranties of any kind, express or implied, including but not limited to\\nwarranties of merchantibility or fitness for any purpose.\\n\\n1.f.5.  some states do not allow disclaimers of certain implied\\nwarranties or the exclusion or limitation of certain types of damages.\\nif any disclaimer or limitation set forth in this agreement violates the\\nlaw of the state applicable to this agreement, the agreement shall be\\ninterpreted to make the maximum disclaimer or limitation permitted by\\nthe applicable state law.  the invalidity or unenforceability of any\\nprovision of this agreement shall not void the remaining provisions.\\n\\n1.f.6.  indemnity - you agree to indemnify and hold the foundation, the\\ntrademark owner, any agent or employee of the foundation, anyone\\nproviding copies of project gutenberg-tm electronic works in accordance\\nwith this agreement, and any volunteers associated with the production,\\npromotion and distribution of project gutenberg-tm electronic works,\\nharmless from all liability, costs and expenses, including legal fees,\\nthat arise directly or indirectly from any of the following which you do\\nor cause to occur: (a) distribution of this or any project gutenberg-tm\\nwork, (b) alteration, modification, or additions or deletions to any\\nproject gutenberg-tm work, and (c) any defect you cause.\\n\\n\\nsection  2.  information about the mission of project gutenberg-tm\\n\\nproject gutenberg-tm is synonymous with the free distribution of\\nelectronic works in formats readable by the widest variety of computers\\nincluding obsolete, old, middle-aged and new computers.  it exists\\nbecause of the efforts of hundreds of volunteers and donations from\\npeople in all walks of life.\\n\\nvolunteers and financial support to provide volunteers with the\\nassistance they need, is critical to reaching project gutenberg-tm\\'s\\ngoals and ensuring that the project gutenberg-tm collection will\\nremain freely available for generations to come.  in 2001, the project\\ngutenberg literary archive foundation was created to provide a secure\\nand permanent future for project gutenberg-tm and future generations.\\nto learn more about the project gutenberg literary archive foundation\\nand how your efforts and donations can help, see sections 3 and 4\\nand the foundation web page at http://www.pglaf.org.\\n\\n\\nsection 3.  information about the project gutenberg literary archive\\nfoundation\\n\\nthe project gutenberg literary archive foundation is a non profit\\n501(c)(3) educational corporation organized under the laws of the\\nstate of mississippi and granted tax exempt status by the internal\\nrevenue service.  the foundation\\'s ein or federal tax identification\\nnumber is 64-6221541.  its 501(c)(3) letter is posted at\\nhttp://pglaf.org/fundraising.  contributions to the project gutenberg\\nliterary archive foundation are tax deductible to the full extent\\npermitted by u.s. federal laws and your state\\'s laws.\\n\\nthe foundation\\'s principal office is located at 4557 melan dr. s.\\nfairbanks, ak, 99712., but its volunteers and employees are scattered\\nthroughout numerous locations.  its business office is located at\\n809 north 1500 west, salt lake city, ut 84116, (801) 596-1887, email\\nbusiness@pglaf.org.  email contact links and up to date contact\\ninformation can be found at the foundation\\'s web site and official\\npage at http://pglaf.org\\n\\nfor additional contact information:\\n     dr. gregory b. newby\\n     chief executive and director\\n     gbnewby@pglaf.org\\n\\n\\nsection 4.  information about donations to the project gutenberg\\nliterary archive foundation\\n\\nproject gutenberg-tm depends upon and cannot survive without wide\\nspread public support and donations to carry out its mission of\\nincreasing the number of public domain and licensed works that can be\\nfreely distributed in machine readable form accessible by the widest\\narray of equipment including outdated equipment.  many small donations\\n($1 to $5,000) are particularly important to maintaining tax exempt\\nstatus with the irs.\\n\\nthe foundation is committed to complying with the laws regulating\\ncharities and charitable donations in all 50 states of the united\\nstates.  compliance requirements are not uniform and it takes a\\nconsiderable effort, much paperwork and many fees to meet and keep up\\nwith these requirements.  we do not solicit donations in locations\\nwhere we have not received written confirmation of compliance.  to\\nsend donations or determine the status of compliance for any\\nparticular state visit http://pglaf.org\\n\\nwhile we cannot and do not solicit contributions from states where we\\nhave not met the solicitation requirements, we know of no prohibition\\nagainst accepting unsolicited donations from donors in such states who\\napproach us with offers to donate.\\n\\ninternational donations are gratefully accepted, but we cannot make\\nany statements concerning tax treatment of donations received from\\noutside the united states.  u.s. laws alone swamp our small staff.\\n\\nplease check the project gutenberg web pages for current donation\\nmethods and addresses.  donations are accepted in a number of other\\nways including checks, online payments and credit card donations.\\nto donate, please visit: http://pglaf.org/donate\\n\\n\\nsection 5.  general information about project gutenberg-tm electronic\\nworks.\\n\\nprofessor michael s. hart is the originator of the project gutenberg-tm\\nconcept of a library of electronic works that could be freely shared\\nwith anyone.  for thirty years, he produced and distributed project\\ngutenberg-tm ebooks with only a loose network of volunteer support.\\n\\n\\nproject gutenberg-tm ebooks are often created from several printed\\neditions, all of which are confirmed as public domain in the u.s.\\nunless a copyright notice is included.  thus, we do not necessarily\\nkeep ebooks in compliance with any particular paper edition.\\n\\n\\nmost people start at our web site which has the main pg search facility:\\n\\n     http://www.gutenberg.org\\n\\nthis web site includes information about project gutenberg-tm,\\nincluding how to make donations to the project gutenberg literary\\narchive foundation, how to help produce our new ebooks, and how to\\nsubscribe to our email newsletter to hear about new ebooks.\\n'"
      ]
     },
     "execution_count": 28,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6AQKlDAOiYvM"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X4jCfVOOVCXe"
   },
   "source": [
    "## Unique Character and char to int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 920
    },
    "colab_type": "code",
    "id": "DZmC1ayMiY0h",
    "outputId": "1392f6b8-7a25-440a-e85c-328f25da87ae"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'\\n': 0,\n",
       " ' ': 1,\n",
       " '!': 2,\n",
       " '\"': 3,\n",
       " '$': 4,\n",
       " '%': 5,\n",
       " \"'\": 6,\n",
       " '(': 7,\n",
       " ')': 8,\n",
       " '*': 9,\n",
       " ',': 10,\n",
       " '-': 11,\n",
       " '.': 12,\n",
       " '/': 13,\n",
       " '0': 14,\n",
       " '1': 15,\n",
       " '2': 16,\n",
       " '3': 17,\n",
       " '4': 18,\n",
       " '5': 19,\n",
       " '6': 20,\n",
       " '7': 21,\n",
       " '8': 22,\n",
       " '9': 23,\n",
       " ':': 24,\n",
       " '@': 25,\n",
       " 'a': 26,\n",
       " 'b': 27,\n",
       " 'c': 28,\n",
       " 'd': 29,\n",
       " 'e': 30,\n",
       " 'f': 31,\n",
       " 'g': 32,\n",
       " 'h': 33,\n",
       " 'i': 34,\n",
       " 'j': 35,\n",
       " 'k': 36,\n",
       " 'l': 37,\n",
       " 'm': 38,\n",
       " 'n': 39,\n",
       " 'o': 40,\n",
       " 'p': 41,\n",
       " 'q': 42,\n",
       " 'r': 43,\n",
       " 's': 44,\n",
       " 't': 45,\n",
       " 'u': 46,\n",
       " 'v': 47,\n",
       " 'w': 48,\n",
       " 'x': 49,\n",
       " 'y': 50,\n",
       " 'z': 51}"
      ]
     },
     "execution_count": 29,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create mapping of unique chars to integers\n",
    "chars = sorted(list(set(raw_text)))\n",
    "char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
    "char_to_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CGLik3HEiY6g"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yVdx906_VsZv"
   },
   "source": [
    "## Total Character and Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "8ZG3XBnciZ0m",
    "outputId": "ef7bf44a-8800-4f6b-dcee-8f803c0b267d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Characters:  18747\n",
      "Total Vocab:  52\n"
     ]
    }
   ],
   "source": [
    "# summarize the loaded data\n",
    "n_chars = len(raw_text)\n",
    "n_vocab = len(chars)\n",
    "print(\"Total Characters: \", n_chars)\n",
    "print(\"Total Vocab: \", n_vocab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a-MYDj94icGc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ar9ZaAM7V-y_"
   },
   "source": [
    "## Feature and Label data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "2gjrLoiwicQF",
    "outputId": "aa930724-ed07-4e5c-80c3-15ded50d2446"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Patterns:  18647\n"
     ]
    }
   ],
   "source": [
    "# prepare the dataset of input to output pairs encoded as integers\n",
    "seq_length = 100\n",
    "dataX = []\n",
    "dataY = []\n",
    "\n",
    "for i in range(0, n_chars - seq_length, 1):\n",
    "  seq_in = raw_text[i:i + seq_length]\n",
    "  seq_out = raw_text[i + seq_length]\n",
    "  dataX.append([char_to_int[char] for char in seq_in])\n",
    "  dataY.append(char_to_int[seq_out])\n",
    "  \n",
    "n_patterns = len(dataX)\n",
    "print(\"Total Patterns: \", n_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9GY9P7A3icbk"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t4yxVu96WG0X"
   },
   "source": [
    "## Reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X-YxIan5icYa"
   },
   "outputs": [],
   "source": [
    "# reshape X to be [samples, time steps, features]\n",
    "X = numpy.reshape(dataX, (n_patterns, seq_length, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "07UlkiS3icTa"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tm0nCJPOWMzj"
   },
   "source": [
    "## Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Fd7pVuslicMN"
   },
   "outputs": [],
   "source": [
    "# normalize\n",
    "X = X / float(n_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4rf8eegpicAa"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w9gqDhLwWPec"
   },
   "source": [
    "## one-hot-encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Fa0R81dqib90"
   },
   "outputs": [],
   "source": [
    "# one hot encode the output variable\n",
    "y = np_utils.to_categorical(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DW4eD8xcib5_"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NCep35d5WSXD"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KUKuoJTfib2B"
   },
   "outputs": [],
   "source": [
    "# define the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2])))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 260
    },
    "colab_type": "code",
    "id": "sgRF0lhyibwS",
    "outputId": "0e16194b-ea2a-4c70-8c88-66e0f05aeaf1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2 (LSTM)                (None, 256)               264192    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 52)                13364     \n",
      "=================================================================\n",
      "Total params: 277,556\n",
      "Trainable params: 277,556\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tdkDujUribty"
   },
   "outputs": [],
   "source": [
    "model.compile(loss= 'categorical_crossentropy' , \n",
    "              optimizer= 'adam' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uMOOqa4wWYRN"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CTg3sE2NWZ71"
   },
   "source": [
    "## Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nq9F_i-Cibr7"
   },
   "outputs": [],
   "source": [
    "# define the checkpoint\n",
    "filepath=\"weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J2COJAlmibnR"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EeGDdSAQWdjH"
   },
   "source": [
    "## Fit Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "mqV8H4-bibj6",
    "outputId": "d16f1df9-7604-45c8-e79d-cbf36c0b1bc4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "18647/18647 [==============================] - 117s 6ms/step - loss: 3.1471\n",
      "\n",
      "Epoch 00001: loss improved from inf to 3.14707, saving model to weights-improvement-01-3.1471.hdf5\n",
      "Epoch 2/20\n",
      "18647/18647 [==============================] - 117s 6ms/step - loss: 3.0872\n",
      "\n",
      "Epoch 00002: loss improved from 3.14707 to 3.08718, saving model to weights-improvement-02-3.0872.hdf5\n",
      "Epoch 3/20\n",
      "18647/18647 [==============================] - 117s 6ms/step - loss: 3.0832\n",
      "\n",
      "Epoch 00003: loss improved from 3.08718 to 3.08320, saving model to weights-improvement-03-3.0832.hdf5\n",
      "Epoch 4/20\n",
      "18647/18647 [==============================] - 118s 6ms/step - loss: 3.0682\n",
      "\n",
      "Epoch 00004: loss improved from 3.08320 to 3.06821, saving model to weights-improvement-04-3.0682.hdf5\n",
      "Epoch 5/20\n",
      "18647/18647 [==============================] - 117s 6ms/step - loss: 3.0470\n",
      "\n",
      "Epoch 00005: loss improved from 3.06821 to 3.04697, saving model to weights-improvement-05-3.0470.hdf5\n",
      "Epoch 6/20\n",
      "18647/18647 [==============================] - 118s 6ms/step - loss: 3.0034\n",
      "\n",
      "Epoch 00006: loss improved from 3.04697 to 3.00341, saving model to weights-improvement-06-3.0034.hdf5\n",
      "Epoch 7/20\n",
      "18647/18647 [==============================] - 116s 6ms/step - loss: 2.9610\n",
      "\n",
      "Epoch 00007: loss improved from 3.00341 to 2.96096, saving model to weights-improvement-07-2.9610.hdf5\n",
      "Epoch 8/20\n",
      "18647/18647 [==============================] - 118s 6ms/step - loss: 2.9172\n",
      "\n",
      "Epoch 00008: loss improved from 2.96096 to 2.91718, saving model to weights-improvement-08-2.9172.hdf5\n",
      "Epoch 9/20\n",
      "18647/18647 [==============================] - 117s 6ms/step - loss: 2.8775\n",
      "\n",
      "Epoch 00009: loss improved from 2.91718 to 2.87747, saving model to weights-improvement-09-2.8775.hdf5\n",
      "Epoch 10/20\n",
      "18647/18647 [==============================] - 116s 6ms/step - loss: 2.7963\n",
      "\n",
      "Epoch 00010: loss improved from 2.87747 to 2.79635, saving model to weights-improvement-10-2.7963.hdf5\n",
      "Epoch 11/20\n",
      "18647/18647 [==============================] - 119s 6ms/step - loss: 2.7112\n",
      "\n",
      "Epoch 00011: loss improved from 2.79635 to 2.71116, saving model to weights-improvement-11-2.7112.hdf5\n",
      "Epoch 12/20\n",
      "18647/18647 [==============================] - 120s 6ms/step - loss: 2.6508\n",
      "\n",
      "Epoch 00012: loss improved from 2.71116 to 2.65083, saving model to weights-improvement-12-2.6508.hdf5\n",
      "Epoch 13/20\n",
      "18647/18647 [==============================] - 119s 6ms/step - loss: 2.6009\n",
      "\n",
      "Epoch 00013: loss improved from 2.65083 to 2.60089, saving model to weights-improvement-13-2.6009.hdf5\n",
      "Epoch 14/20\n",
      "18647/18647 [==============================] - 119s 6ms/step - loss: 2.5523\n",
      "\n",
      "Epoch 00014: loss improved from 2.60089 to 2.55230, saving model to weights-improvement-14-2.5523.hdf5\n",
      "Epoch 15/20\n",
      "18647/18647 [==============================] - 119s 6ms/step - loss: 2.5046\n",
      "\n",
      "Epoch 00015: loss improved from 2.55230 to 2.50463, saving model to weights-improvement-15-2.5046.hdf5\n",
      "Epoch 16/20\n",
      "18647/18647 [==============================] - 119s 6ms/step - loss: 2.4543\n",
      "\n",
      "Epoch 00016: loss improved from 2.50463 to 2.45428, saving model to weights-improvement-16-2.4543.hdf5\n",
      "Epoch 17/20\n",
      "18647/18647 [==============================] - 121s 6ms/step - loss: 2.4111\n",
      "\n",
      "Epoch 00017: loss improved from 2.45428 to 2.41111, saving model to weights-improvement-17-2.4111.hdf5\n",
      "Epoch 18/20\n",
      "18647/18647 [==============================] - 119s 6ms/step - loss: 2.3710\n",
      "\n",
      "Epoch 00018: loss improved from 2.41111 to 2.37099, saving model to weights-improvement-18-2.3710.hdf5\n",
      "Epoch 19/20\n",
      "18647/18647 [==============================] - 120s 6ms/step - loss: 2.3212\n",
      "\n",
      "Epoch 00019: loss improved from 2.37099 to 2.32116, saving model to weights-improvement-19-2.3212.hdf5\n",
      "Epoch 20/20\n",
      "18647/18647 [==============================] - 118s 6ms/step - loss: 2.2729\n",
      "\n",
      "Epoch 00020: loss improved from 2.32116 to 2.27295, saving model to weights-improvement-20-2.2729.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f4f965746d8>"
      ]
     },
     "execution_count": 39,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model\n",
    "model.fit(X, y, epochs=20, batch_size=128, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DcoKmY_Gibij"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kPcie2X0ibdj"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pM0oaxvCiba2"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hqNOWkMUibXn"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NWNj8GapkE7i"
   },
   "source": [
    "Generating Text with an LSTM Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BSwW17ZYibVk"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UzA9UVEbibSm"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3gS0jC18ymg9"
   },
   "source": [
    "## Reading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8dlvgSJbibM9"
   },
   "outputs": [],
   "source": [
    "# load ascii text and covert to lowercase\n",
    "filename = \"/content/drive/My Drive/to-download/the end.txt\"\n",
    "raw_text = open(filename).read()\n",
    "raw_text = raw_text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "865C4xZxibKj"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Wdt_vgwbibIQ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l2nrXwe-ysoX"
   },
   "source": [
    "## Unique Character and int-to char, char-to-int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "otcnUUR7ibEh"
   },
   "outputs": [],
   "source": [
    "# create mapping of unique chars to integers, and a reverse mapping\n",
    "chars = sorted(list(set(raw_text)))\n",
    "char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
    "int_to_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Nsb4Oe7YibBu"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-ccgagq6ia-Y"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nn8kMBwKy6IG"
   },
   "source": [
    "## Total char and vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "pEJjOBlpia8m",
    "outputId": "13e396a4-6ebc-4e0a-a37d-b5672ccfe4d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Characters:  18747\n",
      "Total Vocab:  52\n"
     ]
    }
   ],
   "source": [
    "# summarize the loaded data\n",
    "n_chars = len(raw_text)\n",
    "n_vocab = len(chars)\n",
    "print(\"Total Characters: \", n_chars)\n",
    "print(\"Total Vocab: \", n_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jccJ7FJ3ia57"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZDHtPazLia1N"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AA4Rx7jFzDIP"
   },
   "source": [
    "## Feature and Label data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "J2-SuTI4iayg",
    "outputId": "b6e3bf11-dbec-474e-c509-2193b468da6b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Patterns:  18647\n"
     ]
    }
   ],
   "source": [
    "# prepare the dataset of input to output pairs encoded as integers\n",
    "seq_length = 100\n",
    "dataX = []\n",
    "dataY = []\n",
    "\n",
    "for i in range(0, n_chars - seq_length, 1):\n",
    "  seq_in = raw_text[i:i + seq_length]\n",
    "  seq_out = raw_text[i + seq_length]\n",
    "  dataX.append([char_to_int[char] for char in seq_in])\n",
    "  dataY.append(char_to_int[seq_out])\n",
    "  \n",
    "n_patterns = len(dataX)\n",
    "print(\"Total Patterns: \", n_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FponmbR3iavd"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V0hXvR13ias9"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KBblsh4TZXNU"
   },
   "source": [
    "## Reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MPhEOWUMiapa"
   },
   "outputs": [],
   "source": [
    "# reshape X to be [samples, time steps, features]\n",
    "X = numpy.reshape(dataX, (n_patterns, seq_length, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gzaiytPiiamw"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "POO1QpGXiajk"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yxFt1eyRZZUy"
   },
   "source": [
    "## Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_0I6IIq4iag2"
   },
   "outputs": [],
   "source": [
    "# normalize\n",
    "X = X / float(n_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nPk8oaSdiael"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GQfJLaSczKj5"
   },
   "source": [
    "## One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Wb12yWG3iaZC"
   },
   "outputs": [],
   "source": [
    "# one hot encode the output variable\n",
    "y = np_utils.to_categorical(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "17ZD03ZliaVY"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OIZqYwmCzNem"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DPOA7LWyiaIF"
   },
   "outputs": [],
   "source": [
    "# define the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2])))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 260
    },
    "colab_type": "code",
    "id": "pvSkZWg4iaFX",
    "outputId": "dce23b0b-1e57-4e15-a4bc-15ef3bbe0b0a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_3 (LSTM)                (None, 256)               264192    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 52)                13364     \n",
      "=================================================================\n",
      "Total params: 277,556\n",
      "Trainable params: 277,556\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EVXufZfaiaDB"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer='adam')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dHQbiPWRzfp8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AIuUJB2GzgBL"
   },
   "source": [
    "## Weight of the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RUghrXlviZ_y"
   },
   "outputs": [],
   "source": [
    "# load the network weights\n",
    "filename = \"/content/weights-improvement-20-2.3620.hdf5\"\n",
    "model.load_weights(filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Fl6WOdYwiZ6q"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SU8LoETXzsZD"
   },
   "source": [
    "## Random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "id": "WQ6VC_6EiZ4j",
    "outputId": "84745715-45fb-4a08-d57c-604cc537b52c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:\n",
      "\" gutenberg-tm work, and (c) any defect you cause.\n",
      "\n",
      "\n",
      "section  2.  information about the mission of pro \"\n"
     ]
    }
   ],
   "source": [
    "# pick a random seed\n",
    "start = numpy.random.randint(0, len(dataX)-1)\n",
    "pattern = dataX[start]\n",
    "print(\"Seed:\")\n",
    "print(\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n1vzWbTTiZxz"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OR4xy0Nt5_Tf"
   },
   "source": [
    "## Generate character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "GSWSYM1CiZuS",
    "outputId": "d030a1a6-96ea-4fc2-d9d5-10df0380eaae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " pro ie the  ao ao                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# generate characters\n",
    "for i in range(1000):\n",
    "  x = numpy.reshape(pattern, (1, len(pattern), 1))\n",
    "  x = x / float(n_vocab)\n",
    "  prediction = model.predict(x, verbose=0)\n",
    "  index = numpy.argmax(prediction)\n",
    "  result = int_to_char[index]\n",
    "  seq_in = [int_to_char[value] for value in pattern]\n",
    "  sys.stdout.write(result)\n",
    "  pattern.append(index)\n",
    "  pattern = pattern[1:len(pattern)]\n",
    "print(\"\\nDone.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5DzTZrm7iZl3"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ptg73DVQiZjH"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v88T2S-PiZgs"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2aA5ltBOiZeA"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ucy27yg1kyQ9"
   },
   "source": [
    "Larger LSTM Recurrent Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X2Eq363YiZac"
   },
   "outputs": [],
   "source": [
    "# Larger LSTM Network to Generate Text for Alice in Wonderland\n",
    "import numpy\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nJbDD1_ZiZXu"
   },
   "outputs": [],
   "source": [
    "# load ascii text and covert to lowercase\n",
    "filename = \"/content/drive/My Drive/to-download/the end.txt\"\n",
    "raw_text = open(filename).read()\n",
    "raw_text = raw_text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WjPVAi_PiZU5"
   },
   "outputs": [],
   "source": [
    "raw_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VisM2v7tiZTP"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bR9GIacr0qLf"
   },
   "source": [
    "## Unique char and char-to-int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LTkeP09jiZQX"
   },
   "outputs": [],
   "source": [
    "# create mapping of unique chars to integers\n",
    "chars = sorted(list(set(raw_text)))\n",
    "char_to_int = dict((c, i) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 920
    },
    "colab_type": "code",
    "id": "9d6tVdleiZN-",
    "outputId": "eff958f7-edf3-409f-c4dc-12a3d3c7a165"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'\\n': 0,\n",
       " ' ': 1,\n",
       " '!': 2,\n",
       " '\"': 3,\n",
       " '$': 4,\n",
       " '%': 5,\n",
       " \"'\": 6,\n",
       " '(': 7,\n",
       " ')': 8,\n",
       " '*': 9,\n",
       " ',': 10,\n",
       " '-': 11,\n",
       " '.': 12,\n",
       " '/': 13,\n",
       " '0': 14,\n",
       " '1': 15,\n",
       " '2': 16,\n",
       " '3': 17,\n",
       " '4': 18,\n",
       " '5': 19,\n",
       " '6': 20,\n",
       " '7': 21,\n",
       " '8': 22,\n",
       " '9': 23,\n",
       " ':': 24,\n",
       " '@': 25,\n",
       " 'a': 26,\n",
       " 'b': 27,\n",
       " 'c': 28,\n",
       " 'd': 29,\n",
       " 'e': 30,\n",
       " 'f': 31,\n",
       " 'g': 32,\n",
       " 'h': 33,\n",
       " 'i': 34,\n",
       " 'j': 35,\n",
       " 'k': 36,\n",
       " 'l': 37,\n",
       " 'm': 38,\n",
       " 'n': 39,\n",
       " 'o': 40,\n",
       " 'p': 41,\n",
       " 'q': 42,\n",
       " 'r': 43,\n",
       " 's': 44,\n",
       " 't': 45,\n",
       " 'u': 46,\n",
       " 'v': 47,\n",
       " 'w': 48,\n",
       " 'x': 49,\n",
       " 'y': 50,\n",
       " 'z': 51}"
      ]
     },
     "execution_count": 60,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_to_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iJTa5P0aiZMO"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dfuMqU1c0wSx"
   },
   "source": [
    "## summary of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "ADkxAxUNiZIp",
    "outputId": "9d9e8c6c-9722-4f84-e688-51cf8ce10ec3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Characters:  18747\n",
      "Total Vocab:  52\n"
     ]
    }
   ],
   "source": [
    "# summarize the loaded data\n",
    "n_chars = len(raw_text)\n",
    "n_vocab = len(chars)\n",
    "print(\"Total Characters: \", n_chars)\n",
    "print(\"Total Vocab: \", n_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DvLgX4RZiZCn"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9rfW-IdC05D4"
   },
   "source": [
    "## Feature and Label data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "AnReKWDFiY_-",
    "outputId": "ae936475-a6ba-4eaa-ed93-000473b7bd82"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Patterns:  18647\n"
     ]
    }
   ],
   "source": [
    "# prepare the dataset of input to output pairs encoded as integers\n",
    "seq_length = 100\n",
    "dataX = []\n",
    "dataY = []\n",
    "\n",
    "for i in range(0, n_chars - seq_length, 1):\n",
    "  seq_in = raw_text[i:i + seq_length]\n",
    "  seq_out = raw_text[i + seq_length]\n",
    "  dataX.append([char_to_int[char] for char in seq_in])\n",
    "  dataY.append(char_to_int[seq_out])\n",
    "  \n",
    "n_patterns = len(dataX)\n",
    "print(\"Total Patterns: \", n_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DxtNUXwbiYp4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-IngFEfy0_dR"
   },
   "source": [
    "## Reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gQszBMWmiYn0"
   },
   "outputs": [],
   "source": [
    "# reshape X to be [samples, time steps, features]\n",
    "X = numpy.reshape(dataX, (n_patterns, seq_length, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5ia8D5oTiYlb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DVjKBC0G1BwZ"
   },
   "source": [
    "## Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1l9n-AvmiYhP"
   },
   "outputs": [],
   "source": [
    "# normalize\n",
    "X = X / float(n_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GuGV91YeiYbQ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kJMX3tv21EGe"
   },
   "source": [
    "## One-hot-encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JM6NjnmLiYVK"
   },
   "outputs": [],
   "source": [
    "# one hot encode the output variable\n",
    "y = np_utils.to_categorical(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ft9gn02biYNJ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "23KRMHVQ1HjK"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pCHVIXFNiYKk"
   },
   "outputs": [],
   "source": [
    "# define the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(256))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1], activation= 'softmax' ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 330
    },
    "colab_type": "code",
    "id": "HVEcMrh9iX9J",
    "outputId": "dfcbceda-b142-4175-ffde-caf249e1af34"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_4 (LSTM)                (None, 100, 256)          264192    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 100, 256)          0         \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 256)               525312    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 52)                13364     \n",
      "=================================================================\n",
      "Total params: 802,868\n",
      "Trainable params: 802,868\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4kZR63UziX7S"
   },
   "outputs": [],
   "source": [
    "model.compile(loss= 'categorical_crossentropy', \n",
    "              optimizer= 'adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KuF8awys1Nnb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UmVKOeaz1Oft"
   },
   "source": [
    "## callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "14DnLuKjiX3F"
   },
   "outputs": [],
   "source": [
    "# define the checkpoint\n",
    "filepath=\"weights-improvement-{epoch:02d}-{loss:.4f}-bigger.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IT8sKZnniXxL"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IhJzJrAx1YCm"
   },
   "source": [
    "## Model Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 263
    },
    "colab_type": "code",
    "id": "mHifgd0YiXuC",
    "outputId": "4118fc11-8331-467c-d0ca-eb1cc3a0b691"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "18647/18647 [==============================] - 373s 20ms/step - loss: 3.0990\n",
      "\n",
      "Epoch 00001: loss improved from inf to 3.09897, saving model to weights-improvement-01-3.0990-bigger.hdf5\n",
      "Epoch 2/3\n",
      "18647/18647 [==============================] - 375s 20ms/step - loss: 3.0790\n",
      "\n",
      "Epoch 00002: loss improved from 3.09897 to 3.07903, saving model to weights-improvement-02-3.0790-bigger.hdf5\n",
      "Epoch 3/3\n",
      "18647/18647 [==============================] - 376s 20ms/step - loss: 3.0042\n",
      "\n",
      "Epoch 00003: loss improved from 3.07903 to 3.00423, saving model to weights-improvement-03-3.0042-bigger.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f4f95c720b8>"
      ]
     },
     "execution_count": 72,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model\n",
    "model.fit(X, y, epochs=3, batch_size=64, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uiYg224tiXq_"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OfYPvJMbiXog"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wYv-ywJhls_G"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5B56wURDltIs"
   },
   "outputs": [],
   "source": [
    "# Load Larger LSTM network and generate text\n",
    "import sys\n",
    "import numpy\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eDmgDhFdltqt"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TFIFuti71ntE"
   },
   "source": [
    "## Reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "njIJJvZdluXF"
   },
   "outputs": [],
   "source": [
    "# load ascii text and covert to lowercase\n",
    "filename = \"/content/drive/My Drive/to-download/the end.txt\"\n",
    "raw_text = open(filename).read()\n",
    "raw_text = raw_text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OXBXvOq4lux7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UNVxpYFm1rxr"
   },
   "source": [
    "## Unique char and char-to-int, int-to-char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-YtKYOlUlu3Z"
   },
   "outputs": [],
   "source": [
    "# create mapping of unique chars to integers, and a reverse mapping\n",
    "chars = sorted(list(set(raw_text)))\n",
    "char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
    "int_to_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ovAqkmQglvKD"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8VvJ2oxS1x_L"
   },
   "source": [
    "## summary of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "Le0rdw6qlvnn",
    "outputId": "a3fccbbd-b525-4c7a-d684-0cc6bc9ee305"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Characters:  18747\n",
      "Total Vocab:  52\n"
     ]
    }
   ],
   "source": [
    "# summarize the loaded data\n",
    "n_chars = len(raw_text)\n",
    "n_vocab = len(chars)\n",
    "print(\"Total Characters: \", n_chars)\n",
    "print(\"Total Vocab: \", n_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8q4xqco4lv-U"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JNcA3r6U13si"
   },
   "source": [
    "## Feature and Label data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "U2VlyfkTlwmW",
    "outputId": "9bf440fb-e666-4027-f1fc-b95bb663e150"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Patterns:  18647\n"
     ]
    }
   ],
   "source": [
    "# prepare the dataset of input to output pairs encoded as integers\n",
    "seq_length = 100\n",
    "dataX = []\n",
    "dataY = []\n",
    "\n",
    "for i in range(0, n_chars - seq_length, 1):\n",
    "  seq_in = raw_text[i:i + seq_length]\n",
    "  seq_out = raw_text[i + seq_length]\n",
    "  dataX.append([char_to_int[char] for char in seq_in])\n",
    "  dataY.append(char_to_int[seq_out])\n",
    "n_patterns = len(dataX)\n",
    "print(\"Total Patterns: \", n_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fxtgcfiblw0q"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C6GtzU0s188J"
   },
   "source": [
    "## Reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TwPm_AjnlwxQ"
   },
   "outputs": [],
   "source": [
    "# reshape X to be [samples, time steps, features]\n",
    "X = numpy.reshape(dataX, (n_patterns, seq_length, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pxRCmPQHlwvL"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8N7Y11fB2Bd0"
   },
   "source": [
    "## Normalize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "glBPRWWklwjv"
   },
   "outputs": [],
   "source": [
    "# normalize\n",
    "X = X / float(n_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tYJFhtWClweo"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_8TW5_NB2Gbj"
   },
   "source": [
    "## one-hot-encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kr7fE7DJlwa0"
   },
   "outputs": [],
   "source": [
    "# one hot encode the output variable\n",
    "y = np_utils.to_categorical(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VQzqZZLtlwYj"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a4rlGS4E2Ita"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nP8iU_FhlwTD"
   },
   "outputs": [],
   "source": [
    "# define the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(256))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 330
    },
    "colab_type": "code",
    "id": "9eL09YhqlwPr",
    "outputId": "dad6650b-3651-42d0-a933-2da5a75add25"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_6 (LSTM)                (None, 100, 256)          264192    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 100, 256)          0         \n",
      "_________________________________________________________________\n",
      "lstm_7 (LSTM)                (None, 256)               525312    \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 52)                13364     \n",
      "=================================================================\n",
      "Total params: 802,868\n",
      "Trainable params: 802,868\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yFpudI0plwNL"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4pSFGbbh2V37"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NnepM9SM2WwA"
   },
   "source": [
    "## Weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7LVNIYa1lwJc"
   },
   "outputs": [],
   "source": [
    "# load the network weights\n",
    "filename = \"weights-improvement-03-3.0042-bigger.hdf5\"\n",
    "model.load_weights(filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YPWzRBGhlwFB"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Wznk0iRQ2cS3"
   },
   "source": [
    "## Random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "colab_type": "code",
    "id": "EJ4bg3rylv7Z",
    "outputId": "3f809916-9266-49e4-9597-84dfe119c9bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:\n",
      "\" eriodic tax\n",
      "     returns.  royalty payments should be clearly marked as such and\n",
      "     sent to the pr \"\n"
     ]
    }
   ],
   "source": [
    "# pick a random seed\n",
    "start = numpy.random.randint(0, len(dataX)-1)\n",
    "pattern = dataX[start]\n",
    "print(\"Seed:\")\n",
    "print(\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MXLRfKw0lv5Y"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "txB3nQaF2pLp"
   },
   "source": [
    "## Generate character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "HRUMP7Jllvvw",
    "outputId": "84ca3257-b3c4-4386-b909-e865299eaaec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to \n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# generate characters\n",
    "for i in range(1000):\n",
    "  x = numpy.reshape(pattern, (1, len(pattern), 1))\n",
    "  x = x / float(n_vocab)\n",
    "  prediction = model.predict(x, verbose=0)\n",
    "  index = numpy.argmax(prediction)\n",
    "  result = int_to_char[index]\n",
    "  seq_in = [int_to_char[value] for value in pattern]\n",
    "  sys.stdout.write(result)\n",
    "  pattern.append(index)\n",
    "  pattern = pattern[1:len(pattern)]\n",
    "print(\"\\nDone.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R3sdb2Qklvtj"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Text Generation.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
